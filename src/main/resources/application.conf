mongodb {
  uri = "mongodb://localhost:27017/"
  name = "default"
}

mongodb-dispatcher {
  type = Dispatcher
  executor = "thread-pool-executor"
  fork-join-executor {
    parallelism-min = 2
    parallelism-factor = 2.0
    parallelism-max = 10
    task-peeking-mode = "FIFO"
  }
  throughput = 1
}

github-dispatcher {
  type = Dispatcher
  executor = "thread-pool-executor"
  fork-join-executor {
    parallelism-min = 2
    parallelism-factor = 2.0
    parallelism-max = 10
    task-peeking-mode = "FIFO"
  }
  throughput = 1
}

kafka-services {
  bootstrap-servers-config = "localhost:9092"
  key-serializer-class-config = "org.apache.kafka.common.serialization.StringSerializer"
  value-serializer-class-config = "org.apache.kafka.common.serialization.StringSerializer"
  producer-data {
    client-id-config = "KafkaProducer"
    retries-config = 1
  }
  consumer-data {
    group-id-config = "something"
    enable-auto-commit-config = "true"
    auto-commit-interval-ms-config = "1000"
  }
}

spark {
  default {
    mongodb.input.uri = "mongodb://localhost:27017/default"
    mongodb.input.readPreference.name = "secondaryPreferred"
    mongodb.output.uri = "mongodb://localhost:27017/default"
    neo4j.bolt.url = "bolt://127.0.0.1:7687"
    neo4j.bolt.user = "neo4j"
    neo4j.bolt.password = "niger182"
  }
}